const vision = require('@google-cloud/vision');
const sharp = require('sharp');

const { Translate } = require('@google-cloud/translate').v2;
const translate = new Translate();
const client = new vision.ImageAnnotatorClient();
//Liste des objets pour lequels on doit detecter la couleur
const clothesObjects = ['vÃªtement', 'robe', 'pantalon', 'chaussure', 'sac', 't-shirt', 'pull', 'chemise', 'pantalon'];
const luggageObjects = ['valise', 'bagage', 'sac de voyage', 'sac Ã  dos'];

// --- Utilitaires de conversion ---
function toHex(component) {
  const hex = (component || 0).toString(16).toUpperCase();
  return hex.length === 1 ? '0' + hex : hex;
}

// --- Vocabulaire trop gÃ©nÃ©rique Ã  filtrer ---
const genericTerms = [
  "objet", "chose", "Ã©lÃ©ment", "accessoire", "truc", "matÃ©riau",
  "surface", "fond", "conception", "modÃ¨le", "outil", "composant"
];

function isTooGeneric(term) {
  return genericTerms.includes(term.toLowerCase());
}

function regrouperObjets(detectedNames) {
  const noms = detectedNames.map(n => n.toLowerCase());

  if (noms.includes("clÃ©") && noms.includes("porte-clÃ©s")) return ["Trousseau de clÃ©s"];
  if (noms.includes("sac") && noms.includes("dos")) return ["Sac Ã  dos"];
  if (noms.includes("sac") && noms.includes("voyage")) return ["Sac de voyage"];
  if (noms.includes("valise") || noms.includes("bagage")) return ["Valise"];
  if (noms.includes("portable") || noms.includes("tÃ©lÃ©phone")) return ["TÃ©lÃ©phone portable"];

  // Sinon on retourne les 1ers noms traduits
  return [...new Set(detectedNames)].slice(0, 1);
}

// --- Traduction via Google Translate API ---
async function translateToFrench(text) {
  try {
    const [translated] = await translate.translate(text, 'fr');
    return translated;
  } catch (error) {
    console.error("Erreur de traduction :", error.message);
    return text; // fallback en cas dâ€™erreur
  }
}

// Fonction pour dÃ©couper l'image selon une bounding box normalisÃ©e
async function cropImageFromBoundingBox(imageBuffer, boundingPoly) {
  // boundingPoly.normalizedVertices = [{x, y}, ...] avec x,y entre 0 et 1

  // Calcule les min/max des coordonnÃ©es
  const xs = boundingPoly.normalizedVertices.map(v => v.x);
  const ys = boundingPoly.normalizedVertices.map(v => v.y);
  const xMin = Math.min(...xs);
  const xMax = Math.max(...xs);
  const yMin = Math.min(...ys);
  const yMax = Math.max(...ys);

  // Charger lâ€™image avec sharp pour obtenir ses dimensions exactes
  const metadata = await sharp(imageBuffer).metadata();
  const width = metadata.width;
  const height = metadata.height;

  // Calcul coordonnÃ©es en pixels
  const left = Math.round(xMin * width);
  const top = Math.round(yMin * height);
  const cropWidth = Math.round((xMax - xMin) * width);
  const cropHeight = Math.round((yMax - yMin) * height);

  // DÃ©couper lâ€™image
  const croppedBuffer = await sharp(imageBuffer)
    .extract({ left, top, width: cropWidth, height: cropHeight })
    .toBuffer();

  return croppedBuffer;
}


// --- Extraction et filtrage intelligent des labels ---
async function extractRelevantTranslatedLabels(labelAnnotations, max = 3) {
  // 1. Filtrer ceux qui ont un score raisonnable (ex: > 0.6)
  const filteredByScore = labelAnnotations
    .filter(label => label.score >= 0.6)
    .sort((a, b) => b.score - a.score);

  const results = [];

  for (const label of filteredByScore) {
    if (results.length >= max) break;

    const isGeneric = isTooGeneric(label.description);
    const translated = await translateToFrench(label.description);

    // 2. VÃ©rifie que la traduction nâ€™est pas trop gÃ©nÃ©rique non plus
    if (!isGeneric && !isTooGeneric(translated)) {
      results.push(translated);
    }
  }

  // 3. Fallback : si aucun rÃ©sultat pertinent, prendre le top label (mÃªme gÃ©nÃ©rique)
  if (results.length === 0 && labelAnnotations.length > 0) {
    const fallbackTranslated = await translateToFrench(labelAnnotations[0].description);
    results.push(fallbackTranslated);
  }

  return results;
}

//Detection de l'objet dans l'image en utilisant la spacialisation. plus prÃ©cis que la labellisation 
async function detectObjectsWithLocalization(imageBase64) {
  try {
    // Appel Ã  objectLocalization avec l'image en base64
    const [result] = await client.objectLocalization({ image: { content: imageBase64 } });
    const objects = result.localizedObjectAnnotations;

    // Parcours des objets dÃ©tectÃ©s
    objects.forEach(object => {
      console.log(`Objet dÃ©tectÃ© : ${object.name}`);
      console.log(`Confiance : ${object.score}`);

      // CoordonnÃ©es normalisÃ©es de la boÃ®te englobante
      console.log('Bounding box :');
      object.boundingPoly.normalizedVertices.forEach((v, i) =>
        console.log(`  Point ${i + 1}: (x=${v.x}, y=${v.y})`)
      );
    });

    return objects;

  } catch (error) {
    console.error('Erreur objectLocalization:', error);
    throw error;
  }
}
function appartientCategorie(objet, categorieList) {
  return categorieList.includes(objet.toLowerCase());
}

const analyzeImage = async (req, res) => {
  const { imageBase64 } = req.body;

  if (!imageBase64) {
    return res.status(400).json({ error: 'Le fomat de l\'image est incorrect. Foormat de l\'image base64 requise.' });
  }

  try {
      console.log('DÃ©but analyse image');
      const imageBuffer = Buffer.from(imageBase64, 'base64');

    // Localiser objets
//const [localizationResult] = await client.objectLocalization({ image: { content: imageBase64 } });
      const [localizationResult] = await client.objectLocalization({ image: { content: imageBuffer } });

console.log('RÃ©sultat localisation obtenu');

      const localizedObjects = localizationResult.localizedObjectAnnotations;

//if (localizedObjects.length === 0) {
//   return res.status(404).json({ error: 'Aucun objet dÃ©tectÃ©.' });
//}

      // ðŸ›‘ Fallback si aucun objet localisÃ© (ex : clÃ©s non reconnues)
      if (!localizedObjects.length) {
         console.warn("Aucun objet localisÃ©, fallback sur labelDetection");

         const [labelResult] = await client.labelDetection({ image: { content: imageBuffer } });
         const labelNames = await extractRelevantTranslatedLabels(labelResult.labelAnnotations);
         const objets = regrouperObjets(labelNames);

         const [colorResult] = await client.imageProperties({ image: { content: imageBuffer } });
         const colorsRaw = colorResult.imagePropertiesAnnotation?.dominantColors?.colors || [];

         const couleurs = colorsRaw.slice(0, 1).map(color => {
         const rgb = color.color;
         return `#${toHex(rgb.red)}${toHex(rgb.green)}${toHex(rgb.blue)}`;
        });

        return res.json({ objets, couleurs });
      }

    // Premier objet dÃ©tectÃ©
//    const mainObject = localizedObjects[0];
      const translatedNames = [];
      for (const obj of localizedObjects) {
        const name = await translateToFrench(obj.name);
        if (!isTooGeneric(name)) {
          translatedNames.push(name);
        }
      }
const objets = regrouperObjets(translatedNames);

console.log('Objet principal dÃ©tectÃ©:', mainObject.name);

    const translatedName = await translateToFrench(mainObject.name);

console.log('Nom traduit:', translatedName);

    if (isTooGeneric(translatedName)) {
      console.warn(`Nom trop gÃ©nÃ©rique dÃ©tectÃ©: ${translatedName}`);
    }

    // DÃ©cider d'afficher la couleur selon la catÃ©gorie
    const afficherCouleur = clothesObjects.includes(translatedName.toLowerCase()) ||
                           luggageObjects.includes(translatedName.toLowerCase());

    let couleurs = [];

    if (!afficherCouleur) {
      // Renvoi explicite en cas d'objet non pris en charge
        return res.json({
          objets: [translatedName || "inconnu"],
          couleurs: []
        });
    }
    else{
      // DÃ©couper image autour de l'objet
      const croppedImageBuffer = await cropImageFromBoundingBox(imageBuffer, mainObject.boundingPoly);
//const croppedBase64 = croppedImageBuffer.toString('base64');

      // Analyser couleurs sur zone recadrÃ©e
//const [colorResult] = await client.imageProperties({ image: { content: croppedBase64 } });
      const [colorResult] = await client.imageProperties({ image: { content: croppedImageBuffer } });
      const colorsRaw = colorResult.imagePropertiesAnnotation?.dominantColors?.colors || [];

      // Garder la couleur dominante uniquement
      couleurs = colorsRaw.slice(0, 1).map(color => {
        const rgb = color.color;
        return `#${toHex(rgb.red)}${toHex(rgb.green)}${toHex(rgb.blue)}`;
      });
    }

    // Envoyer la rÃ©ponse
    res.json({
      objets: [translatedName],
      couleurs
    });

  } catch (err) {
    if (err.code === 7) {
      console.error('PERMISSION_DENIED : accÃ¨s API refusÃ©.', err);
      return res.status(403).json({ error: 'AccÃ¨s API refusÃ©. Veuillez vÃ©rifier vos droits.' });
    } else if (err.code === 8 || err.code === 429) {
      console.error('RESOURCE_EXHAUSTED ou trop de requÃªtes : quota API Ã©puisÃ©.', err);
      return res.status(429).json({ error: 'Quota API Ã©puisÃ©. RÃ©essayez plus tard.' });
    } else {
      console.error('Erreur serveur durant lâ€™analyse Vision:', err);
      return res.status(500).json({ error: 'Erreur serveur durant lâ€™analyse.' });
    }
  }
};

// --- ContrÃ´leur principal utilisant labelDetection---

//const analyzeImage = async (req, res) => {
//  const { imageBase64 } = req.body;

//  if (!imageBase64) {
//    return res.status(400).json({ error: 'Image base64 requise.' });
//  }

//  console.log('Path vers les credentials :', process.env.GOOGLE_APPLICATION_CREDENTIALS);

//  try {
////const [labelResult] = await client.labelDetection({ image: { content: imageBase64 } });
//    const [localizationResult] = await client.objectLocalization({ image: { content: imageBase64 } });
//    const [colorResult] = await client.imageProperties({ image: { content: imageBase64 } });

//// const objets = await extractRelevantTranslatedLabels(labelResult.labelAnnotations);

   // Ici on rÃ©cupÃ¨re les objets dÃ©tectÃ©s
//    const localizedObjects = localizationResult.localizedObjectAnnotations;

    // Traduction et filtrage identiques Ã  votre fonction extractRelevantTranslatedLabels,
    // mais adaptÃ©e Ã  partir de localizedObjects[].name
//    const objets = [];
//    for (const obj of localizedObjects) {
//      const nomTraduit = await translateToFrench(obj.name);
//      if (!isTooGeneric(nomTraduit)) {
//        objets.push(nomTraduit);
//      }
//      if (objets.length >= 3) break; // Limite max 3 objets
//    }


//    const colorsRaw = colorResult.imagePropertiesAnnotation?.dominantColors?.colors || [];
//    const couleurs = colorsRaw.slice(0, 3).map(color => {
//      const rgb = color.color;
//      return `#${toHex(rgb.red)}${toHex(rgb.green)}${toHex(rgb.blue)}`;
//    });

//    res.json({ objets, couleurs });
//  } catch (err) {
//    console.error('Erreur analyse Vision:', err);
//    res.status(500).json({ error: 'Erreur serveur durant lâ€™analyse.' });
//  }
//};



module.exports = {
  analyzeImage,
  translateToFrench,
};

